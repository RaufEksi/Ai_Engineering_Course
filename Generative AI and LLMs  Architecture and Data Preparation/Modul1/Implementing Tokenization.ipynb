{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtiVlHUnd2PW4OIkroN9ZD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1a9958a7f62a4d28baeeffe8eef98abb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f65600b1a89440a89d2394f99c9cec1c","IPY_MODEL_532d3aab534e4817a22e69b0d274b2a0","IPY_MODEL_a90c488bf8ed4422946d67f0bfcb3be7"],"layout":"IPY_MODEL_a335076e747a43bb8ed3e857b330c9f9"}},"f65600b1a89440a89d2394f99c9cec1c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_399806139aa84c64b62de8495618d46e","placeholder":"​","style":"IPY_MODEL_01a5a4eb2659474fa06cf5956d6a9629","value":"tokenizer_config.json: 100%"}},"532d3aab534e4817a22e69b0d274b2a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4b069c42131462c9d0d2b3f9bf1f607","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72ee28d447ef4b20b44fa5b29e7ee2dd","value":48}},"a90c488bf8ed4422946d67f0bfcb3be7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c2226a2c8054a63b49dbd7bd7670aee","placeholder":"​","style":"IPY_MODEL_c0a79626ba0f4fdaac53331cbd4fc4b7","value":" 48.0/48.0 [00:00&lt;00:00, 811B/s]"}},"a335076e747a43bb8ed3e857b330c9f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"399806139aa84c64b62de8495618d46e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01a5a4eb2659474fa06cf5956d6a9629":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4b069c42131462c9d0d2b3f9bf1f607":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72ee28d447ef4b20b44fa5b29e7ee2dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c2226a2c8054a63b49dbd7bd7670aee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0a79626ba0f4fdaac53331cbd4fc4b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b53fd1c8cfa4313a761ddc9a100e889":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e6e3543db8c46979f09bca2fc3dcabd","IPY_MODEL_9e02dfc3a054402a8e2bfca361f416e3","IPY_MODEL_c472446d29f646a7b12041fc0441c289"],"layout":"IPY_MODEL_c6c8cad0c7634b2aa03545eff55ea7ad"}},"1e6e3543db8c46979f09bca2fc3dcabd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58a561196a074a5288094982bc6e4c64","placeholder":"​","style":"IPY_MODEL_ebf679a9ec514638aeef07d2426e914c","value":"vocab.txt: 100%"}},"9e02dfc3a054402a8e2bfca361f416e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8954fce01ae4871bee8748dbd1a1c38","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f65fc1d55ea49fe84c6e912824cd235","value":231508}},"c472446d29f646a7b12041fc0441c289":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee0616e5a0c142e491dda6f6692cd8aa","placeholder":"​","style":"IPY_MODEL_5735936f86474a519bfde267a5f002ef","value":" 232k/232k [00:00&lt;00:00, 6.44MB/s]"}},"c6c8cad0c7634b2aa03545eff55ea7ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58a561196a074a5288094982bc6e4c64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebf679a9ec514638aeef07d2426e914c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8954fce01ae4871bee8748dbd1a1c38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f65fc1d55ea49fe84c6e912824cd235":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee0616e5a0c142e491dda6f6692cd8aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5735936f86474a519bfde267a5f002ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a0e0dd735b3425da5adee6629249381":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8b3e8e452ef4c609cd9de46bd36cfac","IPY_MODEL_5a0ae29ea6a24331b8a20eeb771026d3","IPY_MODEL_b81423fd061e44479ed64cf34eeb7c84"],"layout":"IPY_MODEL_df63cd4ebfc446a587996a95c0ee88c1"}},"f8b3e8e452ef4c609cd9de46bd36cfac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec31463e495b478baa122c97c1ab37a8","placeholder":"​","style":"IPY_MODEL_8594f9815412439fb34b243e09b0071a","value":"tokenizer.json: 100%"}},"5a0ae29ea6a24331b8a20eeb771026d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82c98653631542cabcdd57ab1c1233a7","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adf8b5f1e281481fbb2cb006327c9036","value":466062}},"b81423fd061e44479ed64cf34eeb7c84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4691d505ef04977b3cb154d89ae850f","placeholder":"​","style":"IPY_MODEL_352979814abb4466b27faa0ee7e096ed","value":" 466k/466k [00:00&lt;00:00, 26.2MB/s]"}},"df63cd4ebfc446a587996a95c0ee88c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec31463e495b478baa122c97c1ab37a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8594f9815412439fb34b243e09b0071a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82c98653631542cabcdd57ab1c1233a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adf8b5f1e281481fbb2cb006327c9036":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4691d505ef04977b3cb154d89ae850f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"352979814abb4466b27faa0ee7e096ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a8da811d96747a195bb4054c19bb9b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b281b5f4ce947fdb04ef2c294744d29","IPY_MODEL_648ec288fef84ec7824a0fb9ed7e2fb3","IPY_MODEL_fddd63e0317c41058c80b6a2295a5be1"],"layout":"IPY_MODEL_e40cbb20ea264722aee5902be26a2cb4"}},"1b281b5f4ce947fdb04ef2c294744d29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbe25c703baa47bea2032336d8edcd3c","placeholder":"​","style":"IPY_MODEL_18486394ba7a4468863652226365c83d","value":"config.json: 100%"}},"648ec288fef84ec7824a0fb9ed7e2fb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce1eb2903a694cf5ab7012ab1d21a601","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e99d1a74b6b489191c348a8253d4656","value":570}},"fddd63e0317c41058c80b6a2295a5be1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b588de5ab9418cac0b777efc0b20fc","placeholder":"​","style":"IPY_MODEL_fb88372fdc484b35972eaaa265678d7c","value":" 570/570 [00:00&lt;00:00, 46.7kB/s]"}},"e40cbb20ea264722aee5902be26a2cb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbe25c703baa47bea2032336d8edcd3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18486394ba7a4468863652226365c83d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce1eb2903a694cf5ab7012ab1d21a601":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e99d1a74b6b489191c348a8253d4656":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43b588de5ab9418cac0b777efc0b20fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb88372fdc484b35972eaaa265678d7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65e7423174ce41629aab04777afc9bcc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75f0a3f575db41dda2b524be03ece947","IPY_MODEL_36ea3cc6a03242d3a18e0bc01f86c824","IPY_MODEL_4090692008a642f68cc07947d6785a63"],"layout":"IPY_MODEL_77438b87f6ab4a318d32d03f78769bff"}},"75f0a3f575db41dda2b524be03ece947":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec825e258af64aa2a363f6e6a2a1f34d","placeholder":"​","style":"IPY_MODEL_654c54b521e34c3498d5e65e34674600","value":"spiece.model: 100%"}},"36ea3cc6a03242d3a18e0bc01f86c824":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c234328ffe5468e991605fc2b6ddebc","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_549444d575db425486de305c0301cbb5","value":798011}},"4090692008a642f68cc07947d6785a63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18fca13b44da48c2b96422edfab420e3","placeholder":"​","style":"IPY_MODEL_87b2628cbdc6478e9a588386c5cbfdc7","value":" 798k/798k [00:00&lt;00:00, 30.7MB/s]"}},"77438b87f6ab4a318d32d03f78769bff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec825e258af64aa2a363f6e6a2a1f34d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"654c54b521e34c3498d5e65e34674600":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c234328ffe5468e991605fc2b6ddebc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"549444d575db425486de305c0301cbb5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18fca13b44da48c2b96422edfab420e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87b2628cbdc6478e9a588386c5cbfdc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32ade87e16a043979f4f554cf70c6520":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_957d2a6d08a04b85838f7b87f3d0dd21","IPY_MODEL_da414a26b267424ab7e880a2f7b0f205","IPY_MODEL_545efb0aa48f475688a3684b22cc513b"],"layout":"IPY_MODEL_4aa596acaadc4f50846d8f647bb52189"}},"957d2a6d08a04b85838f7b87f3d0dd21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06d4e8e67a754d9a8a1a5facbb349191","placeholder":"​","style":"IPY_MODEL_e921fa9876054092a8ae5e2e37eb4d16","value":"tokenizer.json: 100%"}},"da414a26b267424ab7e880a2f7b0f205":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cb34f724ad94f79b74e7b6f8a11083a","max":1382015,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17d51b710b464acab2ae5089e24c2303","value":1382015}},"545efb0aa48f475688a3684b22cc513b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1994a7a068e479aab6b36e1189a1071","placeholder":"​","style":"IPY_MODEL_d670bd7fb21f437abbf1d5791d4dbd34","value":" 1.38M/1.38M [00:00&lt;00:00, 20.3MB/s]"}},"4aa596acaadc4f50846d8f647bb52189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06d4e8e67a754d9a8a1a5facbb349191":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e921fa9876054092a8ae5e2e37eb4d16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cb34f724ad94f79b74e7b6f8a11083a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17d51b710b464acab2ae5089e24c2303":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1994a7a068e479aab6b36e1189a1071":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d670bd7fb21f437abbf1d5791d4dbd34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09381084edb54ab8af4a65403e026c9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1505e9c2b9d74bd99ef01f773c18cdab","IPY_MODEL_2b3669284ecd4e3a9b1b2dd17cc1065b","IPY_MODEL_4eefa904542b492a9d36b599f416676b"],"layout":"IPY_MODEL_59d4dbe440694116b27db88c72fd0181"}},"1505e9c2b9d74bd99ef01f773c18cdab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56af8944f84f4c8c8db746611ba5cfda","placeholder":"​","style":"IPY_MODEL_2c7e484e277448f08005a0035f91213f","value":"config.json: 100%"}},"2b3669284ecd4e3a9b1b2dd17cc1065b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b6cded0a82b4faaa1b58bec9a7cbb11","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c28bb6878ed44d7ea0a64fc555765aa2","value":760}},"4eefa904542b492a9d36b599f416676b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ed0dda74a234479974bebf60163d6a3","placeholder":"​","style":"IPY_MODEL_b2f6b87fab47401d95aa0e31530d95c2","value":" 760/760 [00:00&lt;00:00, 18.5kB/s]"}},"59d4dbe440694116b27db88c72fd0181":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56af8944f84f4c8c8db746611ba5cfda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c7e484e277448f08005a0035f91213f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b6cded0a82b4faaa1b58bec9a7cbb11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c28bb6878ed44d7ea0a64fc555765aa2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ed0dda74a234479974bebf60163d6a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2f6b87fab47401d95aa0e31530d95c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"OfsHC92JGALb","outputId":"9f6cf074-5791-4923-d1f4-5cca3c658fd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n","Collecting transformers==4.42.1\n","  Downloading transformers-4.42.1-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.1) (3.20.3)\n","Collecting huggingface-hub<1.0,>=0.23.2 (from transformers==4.42.1)\n","  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n","Collecting numpy<2.0,>=1.17 (from transformers==4.42.1)\n","  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.1) (26.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.1) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.1) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.1) (2.32.4)\n","Collecting tokenizers<0.20,>=0.19 (from transformers==4.42.1)\n","  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.1) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.1) (4.67.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1) (1.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.1) (4.15.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.42.1) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.42.1) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.42.1) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.42.1) (2026.1.4)\n","Downloading transformers-4.42.1-py3-none-any.whl (9.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, huggingface-hub, tokenizers, transformers\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface_hub 1.4.0\n","    Uninstalling huggingface_hub-1.4.0:\n","      Successfully uninstalled huggingface_hub-1.4.0\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.22.2\n","    Uninstalling tokenizers-0.22.2:\n","      Successfully uninstalled tokenizers-0.22.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 5.0.0\n","    Uninstalling transformers-5.0.0:\n","      Successfully uninstalled transformers-5.0.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed huggingface-hub-0.36.2 numpy-1.26.4 tokenizers-0.19.1 transformers-4.42.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"100e0d57b44a43719d5b5c4c569b1f49"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n","    status = run_func(*args)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n","^C\n"]}],"source":["!pip install nltk\n","!pip install transformers==4.42.1\n","!pip install sentencepiece\n","!pip install spacy\n","!python -m spacy download en_core_web_sm\n","!python -m spacy download de_core_news_sm\n","!pip install scikit-learn\n","!pip install torch==2.2.2\n","!pip install torchtext==0.17.2\n","!pip install numpy==1.26.0"]},{"cell_type":"code","source":["!pip uninstall -y torch torchtext torchvision torchaudio\n","!pip install torch==2.2.2\n","!pip install torchtext==0.17.2\n","import nltk\n","nltk.download(\"punkt\")\n","ltk.download('punkt_tab')\n","import spacy\n","from nltk.tokenize import word_tokenize\n","from nltk.probability import FreqDist\n","from nltk.util import ngrams\n","from transformers import BertTokenizer\n","from transformers import XLNetTokenizer\n","\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn\n","warnings.filterwarnings('ignore')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eh_O2QoEGFc_","executionInfo":{"status":"ok","timestamp":1771273290797,"user_tz":-180,"elapsed":8340,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"109834ba-3a43-46b0-b29a-75d219b25dce"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## What is a tokenizer and why do we use it?\n","\n","Tokenizers play a pivotal role in natural language processing, segmenting text into smaller units known as tokens. These tokens are subsequently transformed into numerical representations called token indices, which are directly employed by deep learning algorithms.\n","<center>\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/images/Tokenization%20lab%20Diagram%201.png\" width=\"50%\" alt=\"Image Description\">\n","</center>\n"],"metadata":{"id":"WncQe9JeGVbA"}},{"cell_type":"markdown","source":["## Types of tokenizer\n","\n","The meaningful representation can vary depending on the model in use. Various models employ distinct tokenization algorithms, and you will broadly cover the following approaches. Transforming text into numerical values might appear straightforward initially, but it encompasses several considerations that must be kept in mind.\n","<center>\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/images/Tokenization%20lab%20Diagram%202.png\" width=\"50%\" alt=\"Image Description\">\n","</center>\n"],"metadata":{"id":"VfLl-FFKGoaq"}},{"cell_type":"markdown","source":["## Word-based tokenizer\n","\n","###  nltk\n","\n","As the name suggests, this is the splitting of text based on words. There are different rules for word-based tokenizers, such as splitting on spaces or splitting on punctuation. Each option assigns a specific ID to the split word. Here you use nltk's  ```word_tokenize```\n"],"metadata":{"id":"13bWC3JJGqw2"}},{"cell_type":"code","source":["text = \"This is a sample sentence for word tokenization\"\n","tokens = word_tokenize(text)\n","print(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiRM5pj1GOts","executionInfo":{"status":"ok","timestamp":1771273298089,"user_tz":-180,"elapsed":36,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"fc858f7d-494d-4357-9de8-a3a37e1836d3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['This', 'is', 'a', 'sample', 'sentence', 'for', 'word', 'tokenization']\n"]}]},{"cell_type":"markdown","source":["General libraries like nltk and spaCy often split words like 'don't' and 'couldn't,' which are contractions, into different individual words. There's no universal rule, and each library has its own tokenization rules for word-based tokenizers. However, the general guideline is to preserve the input format after tokenization to match how the model was trained.\n"],"metadata":{"id":"8A_QEkq-G4KH"}},{"cell_type":"code","source":["text = \"I don't like this movie. It's terrible.\"\n","tokens = word_tokenize(text)\n","print(tokens)\n","#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8a7TKP1DG5_R","executionInfo":{"status":"ok","timestamp":1771273300289,"user_tz":-180,"elapsed":15,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"2a4c2703-e556-4724-a195-0f580ff549bd"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['I', 'do', \"n't\", 'like', 'this', 'movie', '.', 'It', \"'s\", 'terrible', '.']\n"]}]},{"cell_type":"code","source":["text = \"I don't like this movie. It's terrible.\"\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(text)\n","\n","token_list = [token.text for token in doc]\n","print(\"Tokens: \",token_list)\n","\n","\n","for token in doc:\n","  print(token.text, token.pos_, token.dep_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ei57-CsTG9ov","executionInfo":{"status":"ok","timestamp":1771273308216,"user_tz":-180,"elapsed":2232,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"19c2d473-71af-4b35-9458-c89e114867f8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokens:  ['I', 'do', \"n't\", 'like', 'this', 'movie', '.', 'It', \"'s\", 'terrible', '.']\n","I PRON nsubj\n","do AUX aux\n","n't PART neg\n","like VERB ROOT\n","this DET det\n","movie NOUN dobj\n",". PUNCT punct\n","It PRON nsubj\n","'s AUX ROOT\n","terrible ADJ acomp\n",". PUNCT punct\n"]}]},{"cell_type":"code","source":["text = \"Unicorns are real. I saw a unicorn yesterday\"\n","token = word_tokenize(text)\n","print(token)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SfCawxc1HOKl","executionInfo":{"status":"ok","timestamp":1771273357664,"user_tz":-180,"elapsed":16,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"98346fef-a722-4c5f-f1d5-b4d28cf873cd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['Unicorns', 'are', 'real', '.', 'I', 'saw', 'a', 'unicorn', 'yesterday']\n"]}]},{"cell_type":"markdown","source":["## Character-based tokenizer\n","\n","As the name suggests, character-based tokenization involves splitting text into individual characters. The advantage of using this approach is that the resulting vocabularies are inherently small. Furthermore, since languages have a limited set of characters, the number of out-of-vocabulary tokens is also limited, reducing token wastage.\n","\n","For example:\n","Input text: `This is a sample sentence for tokenization.`\n","\n","Character-based tokenization output: `['T', 'h', 'i', 's', 'i', 's', 'a', 's', 'a', 'm', 'p', 'l', 'e', 's', 'e', 'n', 't', 'e', 'n', 'c', 'e', 'f', 'o', 'r', 't', 'o', 'k', 'e', 'n', 'i', 'z', 'a', 't', 'i', 'o', 'n', '.']`\n","\n","However, it's important to note that character-based tokenization has its limitations. Single characters may not convey the same information as entire words, and the overall token length increases significantly, potentially causing issues with model size and a loss of performance.\n"],"metadata":{"id":"Y_aAG864HroK"}},{"cell_type":"markdown","source":["## Subword-based tokenizer\n","\n","The subword-based tokenizer allows frequently used words to remain unsplit while breaking down infrequent words into meaningful subwords. Techniques such as SentencePiece, or WordPiece are commonly used for subword tokenization. These methods learn subword units from a given text corpus, identifying common prefixes, suffixes, and root words as subword tokens based on their frequency of occurrence. This approach offers the advantage of representing a broader range of words and adapting to the specific language patterns within a text corpus.\n","\n","In both examples below, words are split into subwords, which helps preserve the semantic information associated with the overall word. For instance, 'Unhappiness' is split into 'un' and 'happiness,' both of which can appear as stand-alone subwords. When we combine these individual subwords, they form 'unhappiness,' which retains its meaningful context. This approach aids in maintaining the overall information and semantic meaning of words.\n","\n","<center>\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0201EN-Coursera/images/Tokenization%20lab%20Diagram%203.png\" width=\"50%\" alt=\"Image Description\">\n","</center>\n"],"metadata":{"id":"Ng4ynsWOHt0y"}},{"cell_type":"markdown","source":["### WordPiece\n","\n","Initially, WordPiece initializes its vocabulary to include every character present in the training data and progressively learns a specified number of merge rules. WordPiece doesn't select the most frequent symbol pair but rather the one that maximizes the likelihood of the training data when added to the vocabulary. In essence, WordPiece evaluates what it sacrifices by merging two symbols to ensure it's a worthwhile endeavor.\n","\n","Now, the WordPiece tokenizer is implemented in BertTokenizer.\n","Note that BertTokenizer treats composite words as separate tokens."],"metadata":{"id":"EO8ywIPOHv6O"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","tokenizer.tokenize(\"IBM taught me tokenization\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162,"referenced_widgets":["1a9958a7f62a4d28baeeffe8eef98abb","f65600b1a89440a89d2394f99c9cec1c","532d3aab534e4817a22e69b0d274b2a0","a90c488bf8ed4422946d67f0bfcb3be7","a335076e747a43bb8ed3e857b330c9f9","399806139aa84c64b62de8495618d46e","01a5a4eb2659474fa06cf5956d6a9629","a4b069c42131462c9d0d2b3f9bf1f607","72ee28d447ef4b20b44fa5b29e7ee2dd","7c2226a2c8054a63b49dbd7bd7670aee","c0a79626ba0f4fdaac53331cbd4fc4b7","5b53fd1c8cfa4313a761ddc9a100e889","1e6e3543db8c46979f09bca2fc3dcabd","9e02dfc3a054402a8e2bfca361f416e3","c472446d29f646a7b12041fc0441c289","c6c8cad0c7634b2aa03545eff55ea7ad","58a561196a074a5288094982bc6e4c64","ebf679a9ec514638aeef07d2426e914c","f8954fce01ae4871bee8748dbd1a1c38","1f65fc1d55ea49fe84c6e912824cd235","ee0616e5a0c142e491dda6f6692cd8aa","5735936f86474a519bfde267a5f002ef","4a0e0dd735b3425da5adee6629249381","f8b3e8e452ef4c609cd9de46bd36cfac","5a0ae29ea6a24331b8a20eeb771026d3","b81423fd061e44479ed64cf34eeb7c84","df63cd4ebfc446a587996a95c0ee88c1","ec31463e495b478baa122c97c1ab37a8","8594f9815412439fb34b243e09b0071a","82c98653631542cabcdd57ab1c1233a7","adf8b5f1e281481fbb2cb006327c9036","a4691d505ef04977b3cb154d89ae850f","352979814abb4466b27faa0ee7e096ed","4a8da811d96747a195bb4054c19bb9b1","1b281b5f4ce947fdb04ef2c294744d29","648ec288fef84ec7824a0fb9ed7e2fb3","fddd63e0317c41058c80b6a2295a5be1","e40cbb20ea264722aee5902be26a2cb4","bbe25c703baa47bea2032336d8edcd3c","18486394ba7a4468863652226365c83d","ce1eb2903a694cf5ab7012ab1d21a601","4e99d1a74b6b489191c348a8253d4656","43b588de5ab9418cac0b777efc0b20fc","fb88372fdc484b35972eaaa265678d7c"]},"id":"XIdx7ehRHohx","executionInfo":{"status":"ok","timestamp":1771273424046,"user_tz":-180,"elapsed":1098,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"676e2130-2390-4aa9-f719-1e6c3004a6b5"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a9958a7f62a4d28baeeffe8eef98abb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b53fd1c8cfa4313a761ddc9a100e889"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0e0dd735b3425da5adee6629249381"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8da811d96747a195bb4054c19bb9b1"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["['ibm', 'taught', 'me', 'token', '##ization']"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["### Unigram and SentencePiece\n","\n","Unigram is a method for breaking words or text into smaller pieces. It accomplishes this by starting with a large list of possibilities and gradually narrowing it down based on how frequently those pieces appear in the text. This approach aids in efficient text tokenization.\n","\n","SentencePiece is a tool that takes text, divides it into smaller, more manageable parts, assigns IDs to these segments, and ensures that it does so consistently. Consequently, if you use SentencePiece on the same text repeatedly, you will consistently obtain the same subwords and IDs.\n","\n","Unigram and SentencePiece work together by implementing Unigram's subword tokenization method within the SentencePiece framework. SentencePiece handles subword segmentation and ID assignment, while Unigram's principles guide the vocabulary reduction process to create a more efficient representation of the text data. This combination is particularly valuable for various NLP tasks in which subword tokenization can enhance the performance of language models.\n"],"metadata":{"id":"0kCj6QsuH-G7"}},{"cell_type":"code","source":["tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n","tokenizer.tokenize(\"IBM taught me tokenization.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["65e7423174ce41629aab04777afc9bcc","75f0a3f575db41dda2b524be03ece947","36ea3cc6a03242d3a18e0bc01f86c824","4090692008a642f68cc07947d6785a63","77438b87f6ab4a318d32d03f78769bff","ec825e258af64aa2a363f6e6a2a1f34d","654c54b521e34c3498d5e65e34674600","9c234328ffe5468e991605fc2b6ddebc","549444d575db425486de305c0301cbb5","18fca13b44da48c2b96422edfab420e3","87b2628cbdc6478e9a588386c5cbfdc7","32ade87e16a043979f4f554cf70c6520","957d2a6d08a04b85838f7b87f3d0dd21","da414a26b267424ab7e880a2f7b0f205","545efb0aa48f475688a3684b22cc513b","4aa596acaadc4f50846d8f647bb52189","06d4e8e67a754d9a8a1a5facbb349191","e921fa9876054092a8ae5e2e37eb4d16","7cb34f724ad94f79b74e7b6f8a11083a","17d51b710b464acab2ae5089e24c2303","e1994a7a068e479aab6b36e1189a1071","d670bd7fb21f437abbf1d5791d4dbd34","09381084edb54ab8af4a65403e026c9a","1505e9c2b9d74bd99ef01f773c18cdab","2b3669284ecd4e3a9b1b2dd17cc1065b","4eefa904542b492a9d36b599f416676b","59d4dbe440694116b27db88c72fd0181","56af8944f84f4c8c8db746611ba5cfda","2c7e484e277448f08005a0035f91213f","4b6cded0a82b4faaa1b58bec9a7cbb11","c28bb6878ed44d7ea0a64fc555765aa2","1ed0dda74a234479974bebf60163d6a3","b2f6b87fab47401d95aa0e31530d95c2"]},"id":"orXKVs62H-YP","executionInfo":{"status":"ok","timestamp":1771273454131,"user_tz":-180,"elapsed":694,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"236fb5d3-b896-4d91-d8a5-dec3688d4e39"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65e7423174ce41629aab04777afc9bcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32ade87e16a043979f4f554cf70c6520"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09381084edb54ab8af4a65403e026c9a"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["['▁IBM', '▁taught', '▁me', '▁token', 'ization', '.']"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## Tokenization with PyTorch\n","In PyTorch, especially with the `torchtext` library, the tokenizer breaks down text from a data set into individual words or subwords, facilitating their conversion into numerical format. After tokenization, the vocab (vocabulary) maps these tokens to unique integers, allowing them to be fed into neural networks. This process is vital because deep learning models operate on numerical data and cannot process raw text directly. Thus, tokenization and vocabulary mapping serve as a bridge between human-readable text and machine-operable numerical data. Consider the dataset:\n"],"metadata":{"id":"flakrwXtIDPZ"}},{"cell_type":"code","source":["dataset = [\n","    (1,\"Introduction to NLP\"),\n","    (2,\"Basics of PyTorch\"),\n","    (1,\"NLP Techniques for Text Classification\"),\n","    (3,\"Named Entity Recognition with PyTorch\"),\n","    (3,\"Sentiment Analysis using PyTorch\"),\n","    (3,\"Machine Translation with PyTorch\"),\n","    (1,\" NLP Named Entity,Sentiment Analysis,Machine Translation \"),\n","    (1,\" Machine Translation with NLP \"),\n","    (1,\" Named Entity vs Sentiment Analysis  NLP \")]"],"metadata":{"id":"IPzPHqA4H_7Y","executionInfo":{"status":"ok","timestamp":1771273492126,"user_tz":-180,"elapsed":5,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from torchtext.data.utils import get_tokenizer"],"metadata":{"id":"osg1HcBAIJXu","executionInfo":{"status":"ok","timestamp":1771273499365,"user_tz":-180,"elapsed":7,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenizer = get_tokenizer(\"basic_english\")"],"metadata":{"id":"3M0mX3R-ILI7","executionInfo":{"status":"ok","timestamp":1771273503283,"user_tz":-180,"elapsed":11,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["tokenizer(dataset[0][1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6QnBZ3LsIMGF","executionInfo":{"status":"ok","timestamp":1771273507991,"user_tz":-180,"elapsed":10,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"5c0b7c4a-4fe2-4cf9-dc7d-bd0605f68e68"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['introduction', 'to', 'nlp']"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Token indices\n","You would represent words as numbers as NLP algorithms can process and manipulate numbers more efficiently and quickly than raw text. You use the function **```build_vocab_from_iterator```**, the output is typically referred to as 'token indices' or simply 'indices.' These indices represent the numeric representations of the tokens in the vocabulary.\n","\n","The **```build_vocab_from_iterator```** function, when applied to a list of tokens, assigns a unique index to each token based on its position in the vocabulary. These indices serve as a way to represent the tokens in a numerical format that can be easily processed by machine learning models.\n","\n","For example, given a vocabulary with tokens [\"apple\", \"banana\", \"orange\"], the corresponding indices might be [0, 1, 2], where \"apple\" is represented by index 0, \"banana\" by index 1, and \"orange\" by index 2.\n","\n","**```dataset```** is an iterable. Therefore, you use a generator function yield_tokens to apply the **```tokenizer```**. The purpose of the generator function **```yield_tokens```** is to yield tokenized texts one at a time. Instead of processing the entire dataset and returning all the tokenized texts in one go, the generator function processes and yields each tokenized text individually as it is requested. The tokenization process is performed lazily, which means the next tokenized text is generated only when needed, saving memory and computational resources.\n"],"metadata":{"id":"car3HuN5IT48"}},{"cell_type":"code","source":["def yield_tokens(data_iter):\n","    for  _,text in data_iter:\n","        yield tokenizer(text)"],"metadata":{"id":"4F6SSUpeIVM7","executionInfo":{"status":"ok","timestamp":1771273541649,"user_tz":-180,"elapsed":18,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["my_iterator = yield_tokens(dataset)"],"metadata":{"id":"8GYXzLrPIVdJ","executionInfo":{"status":"ok","timestamp":1771273548101,"user_tz":-180,"elapsed":5,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["next(my_iterator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B__YCK-zIXCZ","executionInfo":{"status":"ok","timestamp":1771273551556,"user_tz":-180,"elapsed":14,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"92cac351-9327-49ab-f3e9-b31df34c75c0"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['introduction', 'to', 'nlp']"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["You build a vocabulary from the tokenized texts generated by the **```yield_tokens```** generator function, which processes the dataset. The **```build_vocab_from_iterator()```** function constructs the vocabulary, including a special token `unk` to represent out-of-vocabulary words.\n","\n","### Out-of-vocabulary (OOV)\n","When text data is tokenized, there may be words that are not present in the vocabulary because they are rare or unseen during the vocabulary building process. When encountering such OOV words during actual language processing tasks like text generation or language modeling, the model can use the ```<unk>``` token to represent them.\n","\n","For example, if the word \"apple\" is present in the vocabulary, but \"pineapple\" is not, \"apple\" will be used normally in the text, but \"pineapple\" (being an OOV word) would be replaced by the ```<unk>``` token.\n","\n","By including the `<unk>` token in the vocabulary, you provide a consistent way to handle out-of-vocabulary words in your language model or other natural language processing tasks.\n"],"metadata":{"id":"v1dl9eyEIa74"}},{"cell_type":"code","source":["vocab = build_vocab_from_iterator(yield_tokens(dataset), specials=[\"<unk>\"])\n","vocab.set_default_index(vocab[\"<unk>\"])"],"metadata":{"id":"Fu-wHoKHIX4M","executionInfo":{"status":"ok","timestamp":1771273576748,"user_tz":-180,"elapsed":7,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def get_tokenized_sentence_and_indices(iterator):\n","    tokenized_sentence = next(iterator)  # Get the next tokenized sentence\n","    token_indices = [vocab[token] for token in tokenized_sentence]  # Get token indices\n","    return tokenized_sentence, token_indices\n","\n","tokenized_sentence, token_indices = get_tokenized_sentence_and_indices(my_iterator)\n","next(my_iterator)\n","\n","print(\"Tokenized Sentence:\", tokenized_sentence)\n","print(\"Token Indices:\", token_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrpY7A7wIeAi","executionInfo":{"status":"ok","timestamp":1771273584723,"user_tz":-180,"elapsed":14,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"768887c9-79ea-481b-f067-ba190443602d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized Sentence: ['basics', 'of', 'pytorch']\n","Token Indices: [11, 15, 2]\n"]}]},{"cell_type":"code","source":["lines = [\"IBM taught me tokenization\",\n","         \"Special tokenizers are ready and they will blow your mind\",\n","         \"just saying hi!\"]\n","\n","special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n","\n","tokenizer_en = get_tokenizer('spacy', language='en_core_web_sm')\n","\n","tokens = []\n","max_length = 0\n","\n","for line in lines:\n","    tokenized_line = tokenizer_en(line)\n","    tokenized_line = ['<bos>'] + tokenized_line + ['<eos>']\n","    tokens.append(tokenized_line)\n","    max_length = max(max_length, len(tokenized_line))\n","\n","for i in range(len(tokens)):\n","    tokens[i] = tokens[i] + ['<pad>'] * (max_length - len(tokens[i]))\n","\n","print(\"Lines after adding special tokens:\\n\", tokens)\n","\n","# Build vocabulary without unk_init\n","vocab = build_vocab_from_iterator(tokens, specials=['<unk>'])\n","vocab.set_default_index(vocab[\"<unk>\"])\n","\n","# Vocabulary and Token Ids\n","print(\"Vocabulary:\", vocab.get_itos())\n","print(\"Token IDs for 'tokenization':\", vocab.get_stoi())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EbBp9gl7If-Z","executionInfo":{"status":"ok","timestamp":1771273594625,"user_tz":-180,"elapsed":1301,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"b275e426-a089-42f7-aad6-a6d618c9574a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Lines after adding special tokens:\n"," [['<bos>', 'IBM', 'taught', 'me', 'tokenization', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>'], ['<bos>', 'Special', 'tokenizers', 'are', 'ready', 'and', 'they', 'will', 'blow', 'your', 'mind', '<eos>'], ['<bos>', 'just', 'saying', 'hi', '!', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']]\n","Vocabulary: ['<unk>', '<pad>', '<bos>', '<eos>', '!', 'IBM', 'Special', 'and', 'are', 'blow', 'hi', 'just', 'me', 'mind', 'ready', 'saying', 'taught', 'they', 'tokenization', 'tokenizers', 'will', 'your']\n","Token IDs for 'tokenization': {'will': 20, 'tokenizers': 19, 'tokenization': 18, 'taught': 16, 'your': 21, 'saying': 15, '<unk>': 0, 'and': 7, 'hi': 10, '<pad>': 1, '<bos>': 2, 'they': 17, '<eos>': 3, '!': 4, 'ready': 14, 'IBM': 5, 'are': 8, 'Special': 6, 'mind': 13, 'me': 12, 'blow': 9, 'just': 11}\n"]}]},{"cell_type":"markdown","source":["Let's break down the output:\n","1. **Special Tokens**:\n","- Token: \"`<unk>`\", Index: 0: `<unk>` stands for \"unknown\" and represents words that were not seen during vocabulary building, usually during inference on new text.\n","- Token: \"`<pad>`\", Index: 1: `<pad>` is a \"padding\" token used to make sequences of words the same length when batching them together.\n","- Token: \"`<bos>`\", Index: 2: `<bos>` is an acronym for \"beginning of sequence\" and is used to denote the start of a text sequence.\n","- Token: \"`<eos>`\", Index: 3: `<eos>` is an acronym for \"end of sequence\" and is used to denote the end of a text sequence.\n","\n","2. **Word Tokens**:\n","The rest of the tokens are words or punctuation extracted from the provided sentences, each assigned a unique index:\n","- Token: \"IBM\", Index: 5\n","- Token: \"taught\", Index: 16\n","- Token: \"me\", Index: 12\n","    ... and so on.\n","    \n","3. **Vocabulary**:\n","It denotes the total number of tokens in the sentences upon which vocabulary is built.\n","    \n","4. **Token IDs for 'tokenization'**:\n","It represents the token IDs assigned in the vocab where a number represents its presence in the sentence.\n"],"metadata":{"id":"FmW-AM-7IoAG"}},{"cell_type":"code","source":["new_line = \"I learned about embeddings and attention mechanisms.\"\n","\n","# Tokenize the new line\n","tokenized_new_line = tokenizer_en(new_line)\n","tokenized_new_line = ['<bos>'] + tokenized_new_line + ['<eos>']\n","\n","# Pad the new line to match the maximum length of previous lines\n","new_line_padded = tokenized_new_line + ['<pad>'] * (max_length - len(tokenized_new_line))\n","\n","# Convert tokens to IDs and handle unknown words\n","new_line_ids = [vocab[token] if token in vocab else vocab['<unk>'] for token in new_line_padded]\n","\n","# Example usage\n","print(\"Token IDs for new line:\", new_line_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZgPwnz-WIiFB","executionInfo":{"status":"ok","timestamp":1771273624119,"user_tz":-180,"elapsed":10,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"9dd46efa-4503-4f81-ca35-990e4115a24e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Token IDs for new line: [2, 0, 0, 0, 0, 7, 0, 0, 0, 3, 1, 1]\n"]}]},{"cell_type":"markdown","source":["Let's break down the output:\n","\n","1. **Special Tokens**:\n","- Token: \"`<unk>`\", Index: 0: `<unk>` stands for \"unknown\" and represents words that were not seen during vocabulary building, usually during inference on new text.\n","- Token: \"`<pad>`\", Index: 1: `<pad>` is a \"padding\" token used to make sequences of words the same length when batching them together.\n","- Token: \"`<bos>`\", Index: 2: `<bos>` is an acronym for \"beginning of sequence\" and is used to denote the start of a text sequence.\n","- Token: \"`<eos>`\", Index: 3: `<eos>` is an acronym for \"end of sequence\" and is used to denote the end of a text sequence.\n","\n","2. The token **`and`** is recognized in the sentence and it is assigned **`token_id` - 7**.\n"],"metadata":{"id":"UqDqQG_UIrXV"}},{"cell_type":"markdown","source":["## Exercise: Comparative text tokenization and performance analysis\n","- Objective: Evaluate and compare the tokenization capabilities of four different NLP libraries (`nltk`, `spaCy`, `BertTokenizer`, and `XLNetTokenizer`) by analyzing the frequency of tokenized words and measuring the processing time for each tool using `datetime`.\n","- Text for tokenization is as below:\n"],"metadata":{"id":"QPZ8a2pSItRs"}},{"cell_type":"code","source":["text = \"\"\"\n","Going through the world of tokenization has been like walking through a huge maze made of words, symbols, and meanings. Each turn shows a bit more about the cool ways computers learn to understand our language. And while I'm still finding my way through it, the journey’s been enlightening and, honestly, a bunch of fun.\n","Eager to see where this learning path takes me next!\"\n","\"\"\"\n","\n","# Counting and displaying tokens and their frequency\n","from collections import Counter\n","def show_frequencies(tokens, method_name):\n","    print(f\"{method_name} Token Frequencies: {dict(Counter(tokens))}\\n\")"],"metadata":{"id":"CMrs9KqYIpmA","executionInfo":{"status":"ok","timestamp":1771273644500,"user_tz":-180,"elapsed":10,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["import nltk\n","import spacy\n","from transformers import BertTokenizer, XLNetTokenizer\n","from datetime import datetime\n","\n","# NLTK Tokenization\n","start_time = datetime.now()\n","nltk_tokens = nltk.word_tokenize(text)\n","nltk_time = datetime.now() - start_time\n","\n","# SpaCy Tokenization\n","nlp = spacy.load(\"en_core_web_sm\")\n","start_time = datetime.now()\n","spacy_tokens = [token.text for token in nlp(text)]\n","spacy_time = datetime.now() - start_time\n","\n","# BertTokenizer Tokenization\n","bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","start_time = datetime.now()\n","bert_tokens = bert_tokenizer.tokenize(text)\n","bert_time = datetime.now() - start_time\n","\n","# XLNetTokenizer Tokenization\n","xlnet_tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n","start_time = datetime.now()\n","xlnet_tokens = xlnet_tokenizer.tokenize(text)\n","xlnet_time = datetime.now() - start_time\n","\n","# Display tokens, time taken for each tokenizer, and token frequencies\n","print(f\"NLTK Tokens: {nltk_tokens}\\nTime Taken: {nltk_time} seconds\\n\")\n","show_frequencies(nltk_tokens, \"NLTK\")\n","\n","print(f\"SpaCy Tokens: {spacy_tokens}\\nTime Taken: {spacy_time} seconds\\n\")\n","show_frequencies(spacy_tokens, \"SpaCy\")\n","\n","print(f\"Bert Tokens: {bert_tokens}\\nTime Taken: {bert_time} seconds\\n\")\n","show_frequencies(bert_tokens, \"Bert\")\n","\n","print(f\"XLNet Tokens: {xlnet_tokens}\\nTime Taken: {xlnet_time} seconds\\n\")\n","show_frequencies(xlnet_tokens, \"XLNet\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBnyS-LnIukf","executionInfo":{"status":"ok","timestamp":1771273860835,"user_tz":-180,"elapsed":1732,"user":{"displayName":"rauf ekşi","userId":"07760405362537894175"}},"outputId":"c356a8f8-2269-4b4d-b51b-700f82301338"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["NLTK Tokens: ['Going', 'through', 'the', 'world', 'of', 'tokenization', 'has', 'been', 'like', 'walking', 'through', 'a', 'huge', 'maze', 'made', 'of', 'words', ',', 'symbols', ',', 'and', 'meanings', '.', 'Each', 'turn', 'shows', 'a', 'bit', 'more', 'about', 'the', 'cool', 'ways', 'computers', 'learn', 'to', 'understand', 'our', 'language', '.', 'And', 'while', 'I', \"'m\", 'still', 'finding', 'my', 'way', 'through', 'it', ',', 'the', 'journey', '’', 's', 'been', 'enlightening', 'and', ',', 'honestly', ',', 'a', 'bunch', 'of', 'fun', '.', 'Eager', 'to', 'see', 'where', 'this', 'learning', 'path', 'takes', 'me', 'next', '!', \"''\"]\n","Time Taken: 0:00:00.000707 seconds\n","\n","NLTK Token Frequencies: {'Going': 1, 'through': 3, 'the': 3, 'world': 1, 'of': 3, 'tokenization': 1, 'has': 1, 'been': 2, 'like': 1, 'walking': 1, 'a': 3, 'huge': 1, 'maze': 1, 'made': 1, 'words': 1, ',': 5, 'symbols': 1, 'and': 2, 'meanings': 1, '.': 3, 'Each': 1, 'turn': 1, 'shows': 1, 'bit': 1, 'more': 1, 'about': 1, 'cool': 1, 'ways': 1, 'computers': 1, 'learn': 1, 'to': 2, 'understand': 1, 'our': 1, 'language': 1, 'And': 1, 'while': 1, 'I': 1, \"'m\": 1, 'still': 1, 'finding': 1, 'my': 1, 'way': 1, 'it': 1, 'journey': 1, '’': 1, 's': 1, 'enlightening': 1, 'honestly': 1, 'bunch': 1, 'fun': 1, 'Eager': 1, 'see': 1, 'where': 1, 'this': 1, 'learning': 1, 'path': 1, 'takes': 1, 'me': 1, 'next': 1, '!': 1, \"''\": 1}\n","\n","SpaCy Tokens: ['\\n', 'Going', 'through', 'the', 'world', 'of', 'tokenization', 'has', 'been', 'like', 'walking', 'through', 'a', 'huge', 'maze', 'made', 'of', 'words', ',', 'symbols', ',', 'and', 'meanings', '.', 'Each', 'turn', 'shows', 'a', 'bit', 'more', 'about', 'the', 'cool', 'ways', 'computers', 'learn', 'to', 'understand', 'our', 'language', '.', 'And', 'while', 'I', \"'m\", 'still', 'finding', 'my', 'way', 'through', 'it', ',', 'the', 'journey', '’s', 'been', 'enlightening', 'and', ',', 'honestly', ',', 'a', 'bunch', 'of', 'fun', '.', '\\n', 'Eager', 'to', 'see', 'where', 'this', 'learning', 'path', 'takes', 'me', 'next', '!', '\"', '\\n']\n","Time Taken: 0:00:00.042489 seconds\n","\n","SpaCy Token Frequencies: {'\\n': 3, 'Going': 1, 'through': 3, 'the': 3, 'world': 1, 'of': 3, 'tokenization': 1, 'has': 1, 'been': 2, 'like': 1, 'walking': 1, 'a': 3, 'huge': 1, 'maze': 1, 'made': 1, 'words': 1, ',': 5, 'symbols': 1, 'and': 2, 'meanings': 1, '.': 3, 'Each': 1, 'turn': 1, 'shows': 1, 'bit': 1, 'more': 1, 'about': 1, 'cool': 1, 'ways': 1, 'computers': 1, 'learn': 1, 'to': 2, 'understand': 1, 'our': 1, 'language': 1, 'And': 1, 'while': 1, 'I': 1, \"'m\": 1, 'still': 1, 'finding': 1, 'my': 1, 'way': 1, 'it': 1, 'journey': 1, '’s': 1, 'enlightening': 1, 'honestly': 1, 'bunch': 1, 'fun': 1, 'Eager': 1, 'see': 1, 'where': 1, 'this': 1, 'learning': 1, 'path': 1, 'takes': 1, 'me': 1, 'next': 1, '!': 1, '\"': 1}\n","\n","Bert Tokens: ['going', 'through', 'the', 'world', 'of', 'token', '##ization', 'has', 'been', 'like', 'walking', 'through', 'a', 'huge', 'maze', 'made', 'of', 'words', ',', 'symbols', ',', 'and', 'meanings', '.', 'each', 'turn', 'shows', 'a', 'bit', 'more', 'about', 'the', 'cool', 'ways', 'computers', 'learn', 'to', 'understand', 'our', 'language', '.', 'and', 'while', 'i', \"'\", 'm', 'still', 'finding', 'my', 'way', 'through', 'it', ',', 'the', 'journey', '’', 's', 'been', 'en', '##light', '##ening', 'and', ',', 'honestly', ',', 'a', 'bunch', 'of', 'fun', '.', 'eager', 'to', 'see', 'where', 'this', 'learning', 'path', 'takes', 'me', 'next', '!', '\"']\n","Time Taken: 0:00:00.004523 seconds\n","\n","Bert Token Frequencies: {'going': 1, 'through': 3, 'the': 3, 'world': 1, 'of': 3, 'token': 1, '##ization': 1, 'has': 1, 'been': 2, 'like': 1, 'walking': 1, 'a': 3, 'huge': 1, 'maze': 1, 'made': 1, 'words': 1, ',': 5, 'symbols': 1, 'and': 3, 'meanings': 1, '.': 3, 'each': 1, 'turn': 1, 'shows': 1, 'bit': 1, 'more': 1, 'about': 1, 'cool': 1, 'ways': 1, 'computers': 1, 'learn': 1, 'to': 2, 'understand': 1, 'our': 1, 'language': 1, 'while': 1, 'i': 1, \"'\": 1, 'm': 1, 'still': 1, 'finding': 1, 'my': 1, 'way': 1, 'it': 1, 'journey': 1, '’': 1, 's': 1, 'en': 1, '##light': 1, '##ening': 1, 'honestly': 1, 'bunch': 1, 'fun': 1, 'eager': 1, 'see': 1, 'where': 1, 'this': 1, 'learning': 1, 'path': 1, 'takes': 1, 'me': 1, 'next': 1, '!': 1, '\"': 1}\n","\n","XLNet Tokens: ['▁Going', '▁through', '▁the', '▁world', '▁of', '▁token', 'ization', '▁has', '▁been', '▁like', '▁walking', '▁through', '▁a', '▁huge', '▁maze', '▁made', '▁of', '▁words', ',', '▁symbols', ',', '▁and', '▁meaning', 's', '.', '▁Each', '▁turn', '▁shows', '▁a', '▁bit', '▁more', '▁about', '▁the', '▁cool', '▁ways', '▁computers', '▁learn', '▁to', '▁understand', '▁our', '▁language', '.', '▁And', '▁while', '▁I', \"'\", 'm', '▁still', '▁finding', '▁my', '▁way', '▁through', '▁it', ',', '▁the', '▁journey', '’', 's', '▁been', '▁enlighten', 'ing', '▁and', ',', '▁honestly', ',', '▁a', '▁bunch', '▁of', '▁fun', '.', '▁E', 'ager', '▁to', '▁see', '▁where', '▁this', '▁learning', '▁path', '▁takes', '▁me', '▁next', '!', '\"']\n","Time Taken: 0:00:00.000605 seconds\n","\n","XLNet Token Frequencies: {'▁Going': 1, '▁through': 3, '▁the': 3, '▁world': 1, '▁of': 3, '▁token': 1, 'ization': 1, '▁has': 1, '▁been': 2, '▁like': 1, '▁walking': 1, '▁a': 3, '▁huge': 1, '▁maze': 1, '▁made': 1, '▁words': 1, ',': 5, '▁symbols': 1, '▁and': 2, '▁meaning': 1, 's': 2, '.': 3, '▁Each': 1, '▁turn': 1, '▁shows': 1, '▁bit': 1, '▁more': 1, '▁about': 1, '▁cool': 1, '▁ways': 1, '▁computers': 1, '▁learn': 1, '▁to': 2, '▁understand': 1, '▁our': 1, '▁language': 1, '▁And': 1, '▁while': 1, '▁I': 1, \"'\": 1, 'm': 1, '▁still': 1, '▁finding': 1, '▁my': 1, '▁way': 1, '▁it': 1, '▁journey': 1, '’': 1, '▁enlighten': 1, 'ing': 1, '▁honestly': 1, '▁bunch': 1, '▁fun': 1, '▁E': 1, 'ager': 1, '▁see': 1, '▁where': 1, '▁this': 1, '▁learning': 1, '▁path': 1, '▁takes': 1, '▁me': 1, '▁next': 1, '!': 1, '\"': 1}\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"r1A4C2Y-Ji9r"},"execution_count":null,"outputs":[]}]}